{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data.process_utils import parse_file, compile_csv_logs, combine_data_files, remove_tags, create_tag_range\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_directory = Path(os.getcwd()).parents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Review detection counts in raw data files\n",
    "In this first step we will extract the detections from each raw datafile. Counts of line detections are noted to a log file. Low or no detections in a file indicate that the file may not be formatted correctly. Comparing counts between files also allows us to determine file duplicates."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Inputs\n",
    "file_list = [\n",
    "    'INL 2023-04-04 11-23-27.txt',\n",
    "    'INL 2023-04-11.txt',\n",
    "    'INL 2023-04-18 13-49-26.txt',\n",
    "    'INL 2023-04-27 12-09-44.txt',\n",
    "    'INL 2023-05-08 11-40-17.txt',\n",
    "    'INL 2023-05-09 12-05-47.txt',\n",
    "    'INL 2023-05-17 14-56-03.txt',\n",
    "    'INL 2023-06-02 14-43-21.txt',\n",
    "    'INL 2023-06-13 12-24-05.txt',\n",
    "    'INL re-try 2023-04-11.txt',\n",
    "    'MST 05-08 retry.txt',\n",
    "    'MST 2023-04-04 10-02-34.txt',\n",
    "    'MST 2023-04-11.txt',\n",
    "    'MST 2023-04-18 10-24-34.txt',\n",
    "    'MST 2023-04-27.txt',\n",
    "    'MST 2023-05-08 10-21-50.txt',\n",
    "    'MST 2023-05-17 14-12-07.txt',\n",
    "    'MST 2023-06-02 13-58-22.txt',\n",
    "    'MST 2023-06-13 11-15-03.txt',\n",
    "    'Main St 1 2023-04-18 10-24-34.txt',\n",
    "    'Main st 2023-04-27.txt',\n",
    "    'Main st re-try 2023-04-11.txt',\n",
    "    'PAL 2023-04-04 10-36-49.txt',\n",
    "    'PAL 2023-04-11.txt',\n",
    "    'PAL 2023-04-18 12-31-22.txt',\n",
    "    'PAL 2023-04-27 11-54-04.txt',\n",
    "    'PAL 2023-05-08 11-26-16.txt',\n",
    "    'PAL 2023-05-17 14-40-35.txt',\n",
    "    'PAL 2023-06-02 14-25-46.txt',\n",
    "    'PAL 2023-06-13 09-39-00.txt',\n",
    "    'PAL re-try 2023-04-11.txt',\n",
    "    'PAL retry 4-27.txt',\n",
    "    'PLS 2023-04-18 12-31-22.txt']\n",
    "\n",
    "input_directory = project_directory / 'data/raw/2023'\n",
    "interim_directory = project_directory / 'data/interim/2023'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing of \"INL 2023-04-04 11-23-27.txt\" complete.\n",
      "Processing of \"INL 2023-04-11.txt\" complete.\n",
      "Processing of \"INL 2023-04-18 13-49-26.txt\" complete.\n",
      "Processing of \"INL 2023-04-27 12-09-44.txt\" complete.\n",
      "Processing of \"INL 2023-05-08 11-40-17.txt\" complete.\n",
      "Processing of \"INL 2023-05-09 12-05-47.txt\" complete.\n",
      "Processing of \"INL 2023-05-17 14-56-03.txt\" complete.\n",
      "Processing of \"INL 2023-06-02 14-43-21.txt\" complete.\n",
      "Processing of \"INL 2023-06-13 12-24-05.txt\" complete.\n",
      "Processing of \"INL re-try 2023-04-11.txt\" complete.\n",
      "Processing of \"MST 05-08 retry.txt\" complete.\n",
      "Processing of \"MST 2023-04-04 10-02-34.txt\" complete.\n",
      "Processing of \"MST 2023-04-11.txt\" complete.\n",
      "Processing of \"MST 2023-04-18 10-24-34.txt\" complete.\n",
      "Processing of \"MST 2023-04-27.txt\" complete.\n",
      "Processing of \"MST 2023-05-08 10-21-50.txt\" complete.\n",
      "Processing of \"MST 2023-05-17 14-12-07.txt\" complete.\n",
      "Processing of \"MST 2023-06-02 13-58-22.txt\" complete.\n",
      "Processing of \"MST 2023-06-13 11-15-03.txt\" complete.\n",
      "Processing of \"Main St 1 2023-04-18 10-24-34.txt\" complete.\n",
      "Processing of \"Main st 2023-04-27.txt\" complete.\n",
      "Processing of \"Main st re-try 2023-04-11.txt\" complete.\n",
      "Processing of \"PAL 2023-04-04 10-36-49.txt\" complete.\n",
      "Processing of \"PAL 2023-04-11.txt\" complete.\n",
      "Processing of \"PAL 2023-04-18 12-31-22.txt\" complete.\n",
      "Processing of \"PAL 2023-04-27 11-54-04.txt\" complete.\n",
      "Processing of \"PAL 2023-05-08 11-26-16.txt\" complete.\n",
      "Processing of \"PAL 2023-05-17 14-40-35.txt\" complete.\n",
      "Processing of \"PAL 2023-06-02 14-25-46.txt\" complete.\n",
      "Processing of \"PAL 2023-06-13 09-39-00.txt\" complete.\n",
      "Processing of \"PAL re-try 2023-04-11.txt\" complete.\n",
      "Processing of \"PAL retry 4-27.txt\" complete.\n",
      "Processing of \"PLS 2023-04-18 12-31-22.txt\" complete.\n",
      "CSV logs compiled into processing_logs_compiled.csv.\n"
     ]
    }
   ],
   "source": [
    "# Parses each raw file. Removes the lines that do not look like detection information.\n",
    "for file in file_list:\n",
    "    parse_file(input_file=project_directory / input_directory / file, output_dir=interim_directory)\n",
    "\n",
    "# Complies the log generated for each file into one log. Logs contain counts of detections.\n",
    "compile_csv_logs(interim_directory, 'processing_logs_compiled.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Combining the detection data and filtering for valid tag IDs\n",
    "Once we have reviewed the logs and selected the files want to combine we will combine all the detection files and remove unrecognized tags."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 145 duplicate records.\n"
     ]
    }
   ],
   "source": [
    "# Combine the detection data into a dataframe\n",
    "files_to_combine = [\n",
    "    'INL 2023-04-04 11-23-27_detection.csv',\n",
    "    'INL 2023-04-11_detection.csv',\n",
    "    'INL 2023-04-18 13-49-26_detection.csv',\n",
    "    'INL 2023-04-27 12-09-44_detection.csv',\n",
    "    'INL 2023-05-08 11-40-17_detection.csv',\n",
    "    'INL 2023-05-09 12-05-47_detection.csv',\n",
    "    'INL 2023-05-17 14-56-03_detection.csv',\n",
    "    'INL 2023-06-02 14-43-21_detection.csv',\n",
    "    'INL 2023-06-13 12-24-05_detection.csv',\n",
    "    'MST 05-08 retry_detection.csv',\n",
    "    'MST 2023-04-04 10-02-34_detection.csv',\n",
    "    'MST 2023-04-11_detection.csv',\n",
    "    'MST 2023-04-18 10-24-34_detection.csv',\n",
    "    'MST 2023-04-27_detection.csv',\n",
    "    'MST 2023-05-17 14-12-07_detection.csv',\n",
    "    'MST 2023-06-02 13-58-22_detection.csv',\n",
    "    'MST 2023-06-13 11-15-03_detection.csv',\n",
    "    'PAL 2023-04-04 10-36-49_detection.csv',\n",
    "    'PAL 2023-04-11_detection.csv',\n",
    "    'PAL 2023-04-18 12-31-22_detection.csv',\n",
    "    'PAL 2023-05-08 11-26-16_detection.csv',\n",
    "    'PAL 2023-05-17 14-40-35_detection.csv',\n",
    "    'PAL 2023-06-02 14-25-46_detection.csv',\n",
    "    'PAL 2023-06-13 09-39-00_detection.csv',\n",
    "    'PAL retry 4-27_detection.csv',]\n",
    "\n",
    "processed_directory = project_directory / 'data/processed/2023'\n",
    "\n",
    "# Concat files into a dataframe\n",
    "df_combined = combine_data_files(interim_directory, files_to_combine)\n",
    "\n",
    "# Remove site marker tags\n",
    "l_marker_tags = ['0000_0000000000005126', '0000_0000000000012627', '0000_0000000000012617']\n",
    "df_mt_removed = remove_tags(df_combined, l_marker_tags)\n",
    "\n",
    "# Create list of valid fish tags for 2023\n",
    "valid_tags_2023_1 = create_tag_range('900_228000487', (900, 995), pad=3)\n",
    "valid_tags_2023_2 = create_tag_range('900_228000498', (0,211), pad=3)\n",
    "# Add tags for 2022 that may have returned\n",
    "valid_tags_2022_1 = create_tag_range('900_228000487', (501, 899), pad=3)\n",
    "valid_tags_2022_2 = create_tag_range('900_228000487', (996,999), pad=3)\n",
    "\n",
    "valid_tags = valid_tags_2023_1 + valid_tags_2023_2 + valid_tags_2022_1 + valid_tags_2022_2\n",
    "\n",
    "# Filter for valid 2023 fish tags\n",
    "mask_valid = df_mt_removed['TAG'].isin(valid_tags)\n",
    "df_valid_fish = df_mt_removed[mask_valid].reset_index(drop=True)\n",
    "\n",
    "# Check for duplicates on datetime, tag_id, and site\n",
    "m_dups = df_valid_fish.duplicated(subset=['ARR','TAG', 'SCD'], keep=False)\n",
    "if (n_dups := m_dups.sum()) > 0:\n",
    "    print(f\"There are {n_dups} duplicate records.\")\n",
    "else:\n",
    "    print(\"No duplicates detected.\")\n",
    "\n",
    "# Sort the data by datetime and site\n",
    "import pandas as pd\n",
    "df_valid_fish['ARR']= pd.to_datetime(df_valid_fish['ARR'])\n",
    "df_valid_fish = df_valid_fish.sort_values(['SCD', 'ARR'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step3: Inspecting and Removing Duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/j7f7wnld0qd6n2_fcq18rhfm0000gq/T/ipykernel_19241/3873119546.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_valid_fish[m_dups]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      DTY                     ARR TRF           DUR TTY ANT               TAG   \n24072   I 2023-05-09 12:21:39.100   G  00:00:00.000   A  A4  900_228000498159  \\\n24073   S 2023-05-09 12:21:39.100   G  00:00:00.000   A  A4  900_228000498159   \n24175   S 2023-05-09 12:21:39.100   G  00:00:00.000   A  A4  900_228000498159   \n24074   I 2023-05-09 12:21:42.700   G  00:00:00.000   A  A4  900_228000498159   \n24075   S 2023-05-09 12:21:42.700   G  00:00:00.000   A  A4  900_228000498159   \n...    ..                     ...  ..           ...  ..  ..               ...   \n24172   S 2023-05-09 12:28:11.900   G  00:00:00.000   A  A4  900_228000498176   \n24215   S 2023-05-09 12:28:11.900   G  00:00:00.000   A  A4  900_228000498176   \n24173   I 2023-05-09 12:28:13.900   G  00:00:00.000   A  A4  900_228000498176   \n24174   S 2023-05-09 12:28:13.900   G  00:00:00.000   A  A4  900_228000498176   \n24216   S 2023-05-09 12:28:13.900   G  00:00:00.000   A  A4  900_228000498176   \n\n       SCD  NCD  EFA      TSS     SPV ANV ANA NOI  \n24072  INL  NaN  0.8  703/703  1356.5   8  75  50  \n24073  INL  NaN  0.8  703/703  1356.5   8  75  50  \n24175  INL  NaN  0.8  703/703  1356.5   8  75  50  \n24074  INL  NaN  0.8  698/698  1358.0   8  75  50  \n24075  INL  NaN  0.8  698/698  1358.0   8  75  50  \n...    ...  ...  ...      ...     ...  ..  ..  ..  \n24172  INL  NaN  0.8  740/740  1358.5   8  75  50  \n24215  INL  NaN  0.8  740/740  1358.5   8  75  50  \n24173  INL  NaN  0.7  822/822  1358.0   7  75  50  \n24174  INL  NaN  0.8  822/822  1358.0   7  75  50  \n24216  INL  NaN  0.8  822/822  1358.0   7  75  50  \n\n[145 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DTY</th>\n      <th>ARR</th>\n      <th>TRF</th>\n      <th>DUR</th>\n      <th>TTY</th>\n      <th>ANT</th>\n      <th>TAG</th>\n      <th>SCD</th>\n      <th>NCD</th>\n      <th>EFA</th>\n      <th>TSS</th>\n      <th>SPV</th>\n      <th>ANV</th>\n      <th>ANA</th>\n      <th>NOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24072</th>\n      <td>I</td>\n      <td>2023-05-09 12:21:39.100</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498159</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>703/703</td>\n      <td>1356.5</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24073</th>\n      <td>S</td>\n      <td>2023-05-09 12:21:39.100</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498159</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>703/703</td>\n      <td>1356.5</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24175</th>\n      <td>S</td>\n      <td>2023-05-09 12:21:39.100</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498159</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>703/703</td>\n      <td>1356.5</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24074</th>\n      <td>I</td>\n      <td>2023-05-09 12:21:42.700</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498159</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>698/698</td>\n      <td>1358.0</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24075</th>\n      <td>S</td>\n      <td>2023-05-09 12:21:42.700</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498159</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>698/698</td>\n      <td>1358.0</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24172</th>\n      <td>S</td>\n      <td>2023-05-09 12:28:11.900</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498176</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>740/740</td>\n      <td>1358.5</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24215</th>\n      <td>S</td>\n      <td>2023-05-09 12:28:11.900</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498176</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>740/740</td>\n      <td>1358.5</td>\n      <td>8</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24173</th>\n      <td>I</td>\n      <td>2023-05-09 12:28:13.900</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498176</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.7</td>\n      <td>822/822</td>\n      <td>1358.0</td>\n      <td>7</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24174</th>\n      <td>S</td>\n      <td>2023-05-09 12:28:13.900</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498176</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>822/822</td>\n      <td>1358.0</td>\n      <td>7</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24216</th>\n      <td>S</td>\n      <td>2023-05-09 12:28:13.900</td>\n      <td>G</td>\n      <td>00:00:00.000</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>900_228000498176</td>\n      <td>INL</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>822/822</td>\n      <td>1358.0</td>\n      <td>7</td>\n      <td>75</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n<p>145 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Duplicates\n",
    "df_valid_fish[m_dups]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Insights on duplicates from inspecting the raw files:\n",
    "* Two tags have triplicate detections using a unique key of three columns: ['ARR', 'TAG', 'SCD']\n",
    "* They come from files `INL 2023-05-09 12-05-47.txt` and `INL 2023-05-17 14-56-03.txt`\n",
    "* In file `INL 2023-05-09 12-05-47.txt` they appear twice with differing `DTY` values.\n",
    "* They appear once in `INL 2023-05-17 14-56-03.txt`\n",
    "* We will drop duplicate values keeping the last."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 duplicates dropped.\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate values keeping the last\n",
    "m_dups_drop = df_valid_fish.duplicated(subset=['ARR','TAG', 'SCD'], keep='last')\n",
    "df_valid_fish = df_valid_fish[~m_dups_drop]\n",
    "print(f\"{m_dups_drop.sum()} duplicates dropped.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Export Data\n",
    "filename = 'combined_valid-tag_detections_2023data_2023-11-13.csv'\n",
    "df_valid_fish.to_csv(processed_directory / filename, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "TAG\n900_228000487631    3503\n900_228000487705    3488\n900_228000487685    2999\n900_228000487549    2795\n900_228000487901    2309\n                    ... \n900_228000487924       2\n900_228000487927       1\n900_228000498014       1\n900_228000498180       1\n900_228000498038       1\nName: count, Length: 213, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_fish.TAG.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                  TAG  count\n14   900_228000487506    818\n23   900_228000487515    498\n3    900_228000487549   2795\n88   900_228000487576    146\n45   900_228000487581    266\n..                ...    ...\n20   900_228000498206    629\n133  900_228000498207     56\n27   900_228000498208    418\n96   900_228000498210    134\n99   900_228000498211    122\n\n[213 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TAG</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>900_228000487506</td>\n      <td>818</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>900_228000487515</td>\n      <td>498</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>900_228000487549</td>\n      <td>2795</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>900_228000487576</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>900_228000487581</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>900_228000498206</td>\n      <td>629</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>900_228000498207</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>900_228000498208</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>900_228000498210</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>900_228000498211</td>\n      <td>122</td>\n    </tr>\n  </tbody>\n</table>\n<p>213 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_fish.TAG.value_counts().reset_index().sort_values(by='TAG')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
